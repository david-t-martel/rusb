# Ollama AI Assistant Configuration for rusb

[ollama]
# Base URL for Ollama API
base_url = "http://localhost:11434"

# Model to use (options: gemma2:2b, gemma2:9b, codellama, deepseek-coder)
model = "gemma2:2b"

# Temperature for code generation (0.0 = deterministic, 1.0 = creative)
temperature = 0.1

# Maximum tokens to generate
max_tokens = 2048

[analysis]
# Tools to run during project scan
enabled_tools = ["clippy", "rustc", "rustfmt"]

# Severity levels to auto-fix (options: error, warning, suggestion)
auto_fix_severity = ["error", "warning"]

# File patterns to include
include_patterns = ["*.rs"]

# File patterns to exclude
exclude_patterns = ["*/target/*", "*/test_data/*"]

[watch_mode]
# Interval in seconds between scans
interval = 5

# Auto-fix issues when detected
auto_fix = false

# Run tests after fixing
run_tests = true

[git]
# Analyze staged changes before commit
pre_commit_check = true

# Maximum diff size to analyze (characters)
max_diff_size = 5000

[formatting]
# Run rustfmt automatically
auto_format = true

# Rustfmt edition
edition = "2024"

[clippy]
# Clippy lints to deny (fail on these)
deny = ["warnings"]

# Clippy lints to allow
allow = []

[fixes]
# Create backup before applying fixes
create_backup = true

# Backup directory
backup_dir = ".ollama_backups"

# Maximum files to fix in one batch
max_batch_size = 10

[logging]
# Log level (debug, info, warning, error)
level = "info"

# Log file path
file = "tools/ollama_assistant.log"

# Enable verbose output
verbose = false
